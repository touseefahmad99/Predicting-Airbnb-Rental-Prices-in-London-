{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "def load_and_clean_data(filepath='listings.csv.gz'):\n",
        "\n",
        "    print(f\"Step 1: Loading and cleaning data from {filepath}...\")\n",
        "    try:\n",
        "        try:\n",
        "            df = pd.read_csv(filepath, compression='gzip')\n",
        "        except FileNotFoundError:\n",
        "            df = pd.read_csv('listings.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {filepath} or listings.csv not found.\")\n",
        "        return None\n",
        "\n",
        "    # --- Clean 'price' ---\n",
        "    if 'price' not in df.columns:\n",
        "        print(\"Error: 'price' column not found.\")\n",
        "        return None\n",
        "\n",
        "    df['price'] = df['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
        "    df.dropna(subset=['price'], inplace=True)\n",
        "\n",
        "    # --- Clean 'bathrooms_text' ---\n",
        "    if 'bathrooms_text' in df.columns:\n",
        "        df['bathrooms'] = df['bathrooms_text'].str.extract(r'(\\d+\\.?\\d*)').astype(float)\n",
        "    else:\n",
        "        # Fallback if the column is already named 'bathrooms'\n",
        "        df['bathrooms'] = pd.to_numeric(df['bathrooms'], errors='coerce')\n",
        "\n",
        "    # --- Filter Outliers\n",
        "    # Filtering outliers is crucial for model performance\n",
        "    p_05 = df['price'].quantile(0.05)\n",
        "    p_95 = df['price'].quantile(0.95)\n",
        "    df_filtered = df[(df['price'] >= p_05) & (df['price'] <= p_95)].copy()\n",
        "    print(f\"Filtered prices between £{p_05:.2f} (5th) and £{p_95:.2f} (95th).\")\n",
        "\n",
        "    # --- Feature Engineering: Neighbourhoods ---\n",
        "    # One-hot encoding all neighbourhoods is too much.\n",
        "    top_10_neighbourhoods = df_filtered['neighbourhood_cleansed'].value_counts().head(10).index\n",
        "\n",
        "    # Use .loc to avoid SettingWithCopyWarning\n",
        "    df_filtered.loc[:, 'neighbourhood_grouped'] = df_filtered['neighbourhood_cleansed'].apply(\n",
        "        lambda x: x if x in top_10_neighbourhoods else 'Other'\n",
        "    )\n",
        "\n",
        "    print(f\"Loaded and cleaned data. Shape: {df_filtered.shape}\")\n",
        "    return df_filtered\n",
        "\n",
        "def define_and_preprocess(df):\n",
        "\n",
        "    print(\"\\nStep 2: Defining features and preprocessing...\")\n",
        "\n",
        "    # --- Define Features (X) and Target (y) ---\n",
        "    # Select key feature\n",
        "    numerical_features = [\n",
        "        'accommodates', 'bedrooms', 'bathrooms', 'beds',\n",
        "        'number_of_reviews', 'review_scores_rating',\n",
        "        'latitude', 'longitude', 'minimum_nights'\n",
        "    ]\n",
        "\n",
        "    categorical_features = [\n",
        "        'room_type',\n",
        "        'host_is_superhost',\n",
        "        'neighbourhood_grouped' # Use our new engineered feature\n",
        "    ]\n",
        "\n",
        "    # Define X and y\n",
        "    X = df[numerical_features + categorical_features]\n",
        "    y = df['price']\n",
        "\n",
        "    # --- Split Data ---\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    print(f\"Data split: {len(X_train)} train samples, {len(X_test)} test samples.\")\n",
        "\n",
        "    # --- Create Preprocessing Pipelines ---\n",
        "\n",
        "    # Pipeline for numerical features:\n",
        "    # 1. Impute missing values (e.g., 'bedrooms') with the median\n",
        "    # 2. Scale features to a standard range\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # Pipeline for categorical features:\n",
        "    # 1. Impute missing values (e.g., 'host_is_superhost') with the most frequent value\n",
        "    # 2. One-hot encode the categories\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    # --- Combine pipelines with ColumnTransformer ---\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numerical_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "    # --- Apply preprocessing ---\n",
        "    print(\"Fitting preprocessor and transforming data...\")\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "    X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "    # --- Get Feature Names After Encoding ---\n",
        "\n",
        "    cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
        "    all_feature_names = numerical_features + list(cat_feature_names)\n",
        "\n",
        "    return X_train_processed, X_test_processed, y_train, y_test, preprocessor, all_feature_names\n",
        "\n",
        "def run_and_evaluate_models(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Trains and evaluates all three models.\n",
        "    \"\"\"\n",
        "    print(\"\\nStep 3: Training and evaluating models...\")\n",
        "\n",
        "    # Define the models\n",
        "    models = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10),\n",
        "        \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=5)\n",
        "    }\n",
        "\n",
        "    # Store results\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"--- Training {name} ---\")\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        print(f\"--- Evaluating {name} ---\")\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        results[name] = {'r2': r2, 'rmse': rmse, 'model': model}\n",
        "\n",
        "        # --- Answer Part 1 of Research Question (Accuracy) ---\n",
        "        print(f\"R2 Score: {r2:.4f}\")\n",
        "        print(f\"RMSE: £{rmse:.2f}\")\n",
        "        print(\"-\"*(20 + len(name)) + \"\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the full pipeline\n",
        "    df = load_and_clean_data()\n",
        "\n",
        "    if df is not None:\n",
        "        # We still need feature_names for the next step, so we'll keep it in the return\n",
        "        X_train, X_test, y_train, y_test, preprocessor, feature_names = define_and_preprocess(df)\n",
        "\n",
        "        # Pass all necessary data to the evaluation function\n",
        "        results = run_and_evaluate_models(X_train, y_train, X_test, y_test)\n",
        "\n",
        ""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:44: SyntaxWarning: invalid escape sequence '\\$'\n",
            "<>:44: SyntaxWarning: invalid escape sequence '\\$'\n",
            "/tmp/ipython-input-3674163571.py:44: SyntaxWarning: invalid escape sequence '\\$'\n",
            "  df['price'] = df['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Loading and cleaning data from listings.csv.gz...\n",
            "Filtered prices between £40.00 (5th) and £518.00 (95th).\n",
            "Loaded and cleaned data. Shape: (56499, 80)\n",
            "\n",
            "Step 2: Defining features and preprocessing...\n",
            "Data split: 45199 train samples, 11300 test samples.\n",
            "Fitting preprocessor and transforming data...\n",
            "\n",
            "Step 3: Training and evaluating models...\n",
            "--- Training Linear Regression ---\n",
            "--- Evaluating Linear Regression ---\n",
            "R2 Score: 0.5189\n",
            "RMSE: £71.79\n",
            "-------------------------------------\n",
            "\n",
            "--- Training Random Forest ---\n",
            "--- Evaluating Random Forest ---\n",
            "R2 Score: 0.6350\n",
            "RMSE: £62.53\n",
            "---------------------------------\n",
            "\n",
            "--- Training XGBoost ---\n",
            "--- Evaluating XGBoost ---\n",
            "R2 Score: 0.6611\n",
            "RMSE: £60.25\n",
            "---------------------------\n",
            "\n",
            "\n",
            "ML Pipeline Complete. Initial results printed above.\n",
            "Models and results are stored. Ready for feature analysis when you are.\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_1CrGLdgd-b",
        "outputId": "fd7c4f80-6d62-46cc-d2b4-707223bf1044"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}